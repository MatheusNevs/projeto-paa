# ğŸ¤– Gerador de CÃ³digo Python com IA

Sistema completo de geraÃ§Ã£o de cÃ³digo Python usando **Llama 3.1 8B** com fine-tuning via LoRA, interface web moderna em Next.js.

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um assistente de IA especializado em programaÃ§Ã£o Python, capaz de:
- ğŸ’¬ Manter conversas contextualizadas sobre cÃ³digo
- ğŸ”§ Gerar cÃ³digo Python correto e bem comentado
- âš¡ Processar requisiÃ§Ãµes com baixa latÃªncia (otimizado para GPU)
- ğŸ¨ Interface web moderna e responsiva

### Arquitetura

```
projeto-final/
â”œâ”€â”€ ia-server/          # Backend Python - Servidor de IA
â”‚   â”œâ”€â”€ app.py          # API Flask com inferÃªncia do modelo
â”‚   â”œâ”€â”€ adapters/       # LoRA adapters fine-tuned
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env            # ConfiguraÃ§Ãµes
â”‚
â””â”€â”€ web/                # Frontend/Backend Next.js
    â”œâ”€â”€ app/            # AplicaÃ§Ã£o Next.js 15
    â”œâ”€â”€ components/     # Componentes React
    â””â”€â”€ .env            # ConfiguraÃ§Ãµes
```

## ğŸš€ Tecnologias

### Backend IA (ia-server)
- **Python 3.12+**
- **PyTorch 2.1+** com CUDA
- **Transformers 4.36+** (Hugging Face)
- **PEFT** para LoRA adapters
- **Flask 3.0** para API REST
- **bitsandbytes** para quantizaÃ§Ã£o 4-bit

### Frontend (web)
- **Next.js 16.0** (App Router)
- **React 19.2**
- **TypeScript 5**
- **Tailwind CSS 4**
- **react-markdown** para formataÃ§Ã£o
- **react-syntax-highlighter** para highlight de cÃ³digo

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- **Python 3.12+**
- **Node.js 18+** e npm
- **CUDA 12.0+** e GPU NVIDIA compatÃ­vel (recomendado)
- **16GB+ RAM**
- **8GB+ VRAM** na GPU

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/MatheusNevs/projeto-paa.git
cd projeto-paa
```

### 2. Configurar Backend IA

```bash
cd ia-server

# Criar ambiente virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar variÃ¡veis de ambiente
cp .env.example .env
# Edite o .env conforme necessÃ¡rio
```

> **âš ï¸ IMPORTANTE:** A pasta `adapters/` nÃ£o estÃ¡ incluÃ­da no repositÃ³rio devido ao tamanho dos arquivos (160MB). 
> VocÃª precisa obter os adapters LoRA treinados e colocÃ¡-los na pasta `ia-server/adapters/` antes de executar o servidor.
> Os adapters devem conter os arquivos: `adapter_config.json`, `adapter_model.safetensors`, e arquivos do tokenizer.

**ConteÃºdo do `.env`:**
```env
# Caminhos
ADAPTER_PATH=./adapters

# GeraÃ§Ã£o
MAX_TOKENS=512
TEMPERATURE=0.7
TOP_P=0.9

# Flask
FLASK_ENV=production
FLASK_DEBUG=False
```

### 3. Configurar Frontend

```bash
cd ../web

# Instalar dependÃªncias
npm install

# Configurar variÃ¡veis de ambiente
cp .env.example .env
# Edite o .env conforme necessÃ¡rio
```

**ConteÃºdo do `.env`:**
```env
# URL do servidor IA Python (ia-server)
IA_SERVER_URL=http://localhost:5000

# Chave de API (opcional)
IA_API_KEY=dev-key
```

## ğŸ¯ Como Usar

### Iniciar o Servidor IA

```bash
cd ia-server
source .venv/bin/activate
python app.py
```

O servidor estarÃ¡ disponÃ­vel em `http://localhost:5000`

### Iniciar a Interface Web

```bash
cd web
npm run dev
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em `http://localhost:3000`

### Uso da Interface

1. Acesse `http://localhost:3000`
2. Digite sua pergunta ou pedido de cÃ³digo no campo de texto
3. Clique em "Enviar" ou pressione Enter
4. Aguarde a IA gerar o cÃ³digo
5. O cÃ³digo serÃ¡ exibido com syntax highlighting
6. Continue a conversa para refinar o cÃ³digo

## ğŸ”§ API Endpoints

### Backend IA (porta 5000)

#### `GET /health`
Verifica status do servidor e modelo

**Resposta:**
```json
{
  "status": "online",
  "model_loaded": true,
  "device": "cuda",
  "gpu_available": true,
  "gpu_name": "NVIDIA GeForce RTX 3090",
  "gpu_memory": {
    "allocated_gb": 5.2,
    "reserved_gb": 6.0
  }
}
```

#### `POST /generate`
Gera cÃ³digo a partir de prompt ou histÃ³rico de mensagens

**Request Body:**
```json
{
  "messages": [
    {"role": "user", "content": "Crie uma funÃ§Ã£o para calcular fibonacci"},
    {"role": "assistant", "content": "def fibonacci(n): ..."},
    {"role": "user", "content": "Adicione memoizaÃ§Ã£o"}
  ],
  "max_tokens": 512,
  "temperature": 0.7
}
```

**Resposta:**
```json
{
  "success": true,
  "code": "def fibonacci(n, memo={}):\n    ...",
  "tokens_generated": 156,
  "inference_time_ms": 1234.56,
  "model_loaded": true,
  "gpu_memory": {
    "allocated_gb": 5.2,
    "reserved_gb": 6.0
  }
}
```

#### `GET /stats`
EstatÃ­sticas do servidor

#### `POST /clear-cache`
Limpa cache da GPU

## âš¡ CaracterÃ­sticas TÃ©cnicas

### Modelo
- ğŸ“¦ **Llama 3.1 8B Instruct** (4-bit quantizado)
- ğŸ¯ **LoRA Adapters** fine-tuned para Python
- ğŸ”„ **ConversaÃ§Ã£o contextualizada** (atÃ© 10 mensagens)
- âš™ï¸ **QuantizaÃ§Ã£o 4-bit** (bitsandbytes) para eficiÃªncia de memÃ³ria

## ğŸ“Š EspecificaÃ§Ãµes do Modelo

- **Base:** `unsloth/llama-3.1-8b-instruct-bnb-4bit`
- **QuantizaÃ§Ã£o:** 4-bit (bitsandbytes)
- **LoRA Config:**
  - `r=16`
  - `lora_alpha=16`
  - Targets: `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`
- **MemÃ³ria GPU:** ~6GB VRAM
- **Contexto:** AtÃ© 8192 tokens

## ğŸ¨ Interface

A interface web oferece:
- ğŸ’¬ Chat em tempo real com a IA
- ğŸ¨ Syntax highlighting para cÃ³digo Python
- ğŸ“‹ BotÃ£o de copiar cÃ³digo
- ğŸ“Š Indicador de performance (tempo de inferÃªncia)
- ğŸ”„ HistÃ³rico de conversaÃ§Ã£o
- ğŸ“± Design responsivo
- ğŸŒ™ Tema tech/terminal


## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido como trabalho acadÃªmico para a disciplina de Projeto e AnÃ¡lise de Algoritmos (PAA) na Universidade de BrasÃ­lia (UnB).
